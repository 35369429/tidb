// Copyright 2015 PingCAP, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// See the License for the specific language governing permissions and
// limitations under the License.

package filesort

import (
	"container/heap"
	"encoding/binary"
	"io/ioutil"
	"os"
	"path"
	"sort"
	"strconv"

	"github.com/juju/errors"
	"github.com/pingcap/tidb/sessionctx/variable"
	"github.com/pingcap/tidb/util/codec"
	"github.com/pingcap/tidb/util/types"
)

type ComparableRow struct {
	key    []types.Datum
	val    []types.Datum
	handle int64
}

type Item struct {
	index int
	value *ComparableRow
}

// Min-heap of ComparableRows
type RowHeap struct {
	sc     *variable.StatementContext
	items  []*Item
	byDesc []bool
}

func (rh *RowHeap) Len() int { return len(rh.items) }

func (rh *RowHeap) Swap(i, j int) { rh.items[i], rh.items[j] = rh.items[j], rh.items[i] }

func (rh *RowHeap) Less(i, j int) bool {
	for k, desc := range rh.byDesc {
		v1 := rh.items[i].value.key[k]
		v2 := rh.items[j].value.key[k]

		ret, err := v1.CompareDatum(rh.sc, v2)
		if err != nil {
			panic(err)
		}

		if desc {
			ret = -ret
		}

		if ret < 0 {
			return true
		} else if ret > 0 {
			return false
		}
	}
	return false
}

func (rh *RowHeap) Push(x interface{}) {
	rh.items = append(rh.items, x.(*Item))
}

func (rh *RowHeap) Pop() interface{} {
	old := rh.items
	n := len(old)
	x := old[n-1]
	rh.items = old[0 : n-1]
	return x
}

type FileSorter struct {
	keySize   int                        // size of key slice
	valSize   int                        // size of val slice
	bufSize   int                        // size of buf slice
	tmpDir    string                     // working directory for file sort
	sc        *variable.StatementContext // required by Datum comparison
	buf       []*ComparableRow           // in-momory buffer of rows
	files     []string                   // files generated by file sort
	byDesc    []bool                     // whether or not the specific column sorted in descending order
	fetched   bool
	rowHeap   *RowHeap
	fds       []*os.File
	fileCount int
}

func NewFileSorter(sc *variable.StatementContext, keySize int, valSize int, bufSize int, byDesc []bool) (*FileSorter, error) {
	// Sanity checks
	if sc == nil {
		return nil, errors.New("StatementContext is nil")
	}
	if keySize != len(byDesc) {
		return nil, errors.New("mismatch in key size and byDesc slice")
	}
	if keySize <= 0 {
		return nil, errors.New("key size is not positive")
	}
	if valSize <= 0 {
		return nil, errors.New("value size is not positive")
	}
	if bufSize <= 0 {
		return nil, errors.New("buffer size is not positive")
	}

	dir, err := ioutil.TempDir("", "util_filesort")
	if err != nil {
		return nil, errors.Trace(err)
	}

	rh := &RowHeap{sc: sc,
		items:  make([]*Item, 0),
		byDesc: byDesc,
	}

	return &FileSorter{sc: sc,
		keySize:   keySize,
		valSize:   valSize,
		bufSize:   bufSize,
		buf:       make([]*ComparableRow, 0, bufSize),
		files:     make([]string, 0),
		byDesc:    byDesc,
		fetched:   false,
		rowHeap:   rh,
		tmpDir:    dir,
		fds:       make([]*os.File, 0),
		fileCount: 0,
	}, nil
}

func (fs *FileSorter) Len() int { return len(fs.buf) }

func (fs *FileSorter) Swap(i, j int) { fs.buf[i], fs.buf[j] = fs.buf[j], fs.buf[i] }

func (fs *FileSorter) Less(i, j int) bool {
	for k := 0; k < fs.keySize; k++ {
		v1 := fs.buf[i].key[k]
		v2 := fs.buf[j].key[k]

		ret, err := v1.CompareDatum(fs.sc, v2)
		if err != nil {
			panic(err)
		}

		if fs.byDesc[k] {
			ret = -ret
		}

		if ret < 0 {
			return true
		} else if ret > 0 {
			return false
		}
	}
	return false
}

func (fs *FileSorter) uniqueFileName() string {
	ret := path.Join(fs.tmpDir, strconv.Itoa(fs.fileCount))
	fs.fileCount++
	return ret
}

func (fs *FileSorter) flushMemory() error {
	var (
		err        error
		fileName   string
		outputFile *os.File
		outputByte []byte
	)

	sort.Sort(fs)

	fileName = fs.uniqueFileName()

	outputFile, err = os.OpenFile(fileName, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)
	defer outputFile.Close()
	if err != nil {
		return errors.Trace(err)
	}

	for _, row := range fs.buf {
		var body []byte
		var head = make([]byte, 8)

		body, err = codec.EncodeKey(body, row.key...)
		if err != nil {
			return errors.Trace(err)
		}
		body, err = codec.EncodeKey(body, row.val...)
		if err != nil {
			return errors.Trace(err)
		}
		body, err = codec.EncodeKey(body, types.NewIntDatum(row.handle))
		if err != nil {
			return errors.Trace(err)
		}

		binary.BigEndian.PutUint64(head, uint64(len(body)))

		outputByte = append(outputByte, head...)
		outputByte = append(outputByte, body...)
	}

	_, err = outputFile.Write(outputByte)
	if err != nil {
		return errors.Trace(err)
	}

	fs.files = append(fs.files, fileName)
	fs.buf = fs.buf[:0]
	return nil
}

func (fs *FileSorter) Input(key []types.Datum, val []types.Datum, handle int64) error {
	if fs.fetched {
		return errors.New("call input after output")
	}

	// Sanity checks
	if len(key) != fs.keySize {
		return errors.New("mismatch in key size and key slice")
	}
	if len(val) != fs.valSize {
		return errors.New("mismatch in value size and val slice")
	}

	row := &ComparableRow{
		key:    key,
		val:    val,
		handle: handle,
	}
	fs.buf = append(fs.buf, row)

	if len(fs.buf) >= fs.bufSize {
		fs.flushMemory()
	}

	return nil
}

func (fs *FileSorter) Output() (key []types.Datum, val []types.Datum, handle int64, err error) {
	if !fs.fetched {
		if len(fs.buf) > 0 {
			err = fs.flushMemory()
			if err != nil {
				return nil, nil, 0, errors.Trace(err)
			}
		}

		heap.Init(fs.rowHeap)

		for _, fname := range fs.files {
			var fd *os.File
			fd, err = os.Open(fname)
			if err != nil {
				return nil, nil, 0, errors.Trace(err)
			}
			fs.fds = append(fs.fds, fd)
		}

		var (
			n    int
			head = make([]byte, 8)
			dcod = make([]types.Datum, 0, fs.keySize+fs.valSize+1)
		)

		for id, fd := range fs.fds {
			n, err = fd.Read(head)
			if err != nil {
				return nil, nil, 0, errors.Trace(err)
			}
			if n != 8 {
				return nil, nil, 0, errors.New("incorrect header")
			}

			rowSize := int(binary.BigEndian.Uint64(head))

			rowBytes := make([]byte, rowSize)
			n, err = fd.Read(rowBytes)
			if err != nil {
				return nil, nil, 0, errors.Trace(err)
			}
			if n != rowSize {
				return nil, nil, 0, errors.New("incorrect row")
			}

			dcod, err = codec.Decode(rowBytes, fs.keySize+fs.valSize+1)
			if err != nil {
				return nil, nil, 0, errors.Trace(err)
			}

			row := &ComparableRow{
				key:    dcod[:fs.keySize],
				val:    dcod[fs.keySize : fs.keySize+fs.valSize],
				handle: dcod[fs.keySize+fs.valSize:][0].GetInt64(),
			}

			item := &Item{
				index: id,
				value: row,
			}

			heap.Push(fs.rowHeap, item)
		}

		fs.fetched = true
	}

	if fs.rowHeap.Len() > 0 {
		next := heap.Pop(fs.rowHeap).(*Item)

		var (
			n    int
			head = make([]byte, 8)
			dcod = make([]types.Datum, 0, fs.keySize+fs.valSize+1)
		)
		n, err = fs.fds[next.index].Read(head)
		if err == nil && n == 8 {
			rowSize := int(binary.BigEndian.Uint64(head))

			rowBytes := make([]byte, rowSize)
			n, err = fs.fds[next.index].Read(rowBytes)
			if err != nil {
				return nil, nil, 0, errors.Trace(err)
			}
			if n != rowSize {
				return nil, nil, 0, errors.New("incorrect row")
			}

			dcod, err = codec.Decode(rowBytes, fs.keySize+fs.valSize+1)
			if err != nil {
				return nil, nil, 0, errors.Trace(err)
			}

			row := &ComparableRow{
				key:    dcod[:fs.keySize],
				val:    dcod[fs.keySize : fs.keySize+fs.valSize],
				handle: dcod[fs.keySize+fs.valSize:][0].GetInt64(),
			}

			item := &Item{
				index: next.index,
				value: row,
			}

			heap.Push(fs.rowHeap, item)
		}

		return next.value.key, next.value.val, next.value.handle, nil
	} else {
		for _, fd := range fs.fds {
			fd.Close()
		}
		os.RemoveAll(fs.tmpDir)
		return nil, nil, 0, nil
	}
}
